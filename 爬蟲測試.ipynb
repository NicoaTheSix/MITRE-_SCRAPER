{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MITRE ATT&CK爬蟲"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[MITRE ATT&CK網址](https://attack.mitre.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "███╗   ███╗██╗████████╗██████╗ ███████╗     █████╗ ████████╗████████╗██╗    ██████╗██╗  ██╗    ███████╗ ██████╗██████╗  █████╗ ██████╗ ███████╗██████╗ \n",
      "████╗ ████║██║╚══██╔══╝██╔══██╗██╔════╝    ██╔══██╗╚══██╔══╝╚══██╔══╝██║   ██╔════╝██║ ██╔╝    ██╔════╝██╔════╝██╔══██╗██╔══██╗██╔══██╗██╔════╝██╔══██╗\n",
      "██╔████╔██║██║   ██║   ██████╔╝█████╗      ███████║   ██║      ██║████████╗██║     █████╔╝     ███████╗██║     ██████╔╝███████║██████╔╝█████╗  ██████╔╝\n",
      "██║╚██╔╝██║██║   ██║   ██╔══██╗██╔══╝      ██╔══██║   ██║      ██║██╔═██╔═╝██║     ██╔═██╗     ╚════██║██║     ██╔══██╗██╔══██║██╔═══╝ ██╔══╝  ██╔══██╗\n",
      "██║ ╚═╝ ██║██║   ██║   ██║  ██║███████╗    ██║  ██║   ██║      ██║██████║  ╚██████╗██║  ██╗    ███████║╚██████╗██║  ██║██║  ██║██║     ███████╗██║  ██║\n",
      "╚═╝     ╚═╝╚═╝   ╚═╝   ╚═╝  ╚═╝╚══════╝    ╚═╝  ╚═╝   ╚═╝      ╚═╝╚═════╝   ╚═════╝╚═╝  ╚═╝    ╚══════╝ ╚═════╝╚═╝  ╚═╝╚═╝  ╚═╝╚═╝     ╚══════╝╚═╝  ╚═╝\n",
      "                                                                                                                                                       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "███╗   ███╗██╗████████╗██████╗ ███████╗     █████╗ ████████╗████████╗██╗    ██████╗██╗  ██╗    ███████╗ ██████╗██████╗  █████╗ ██████╗ ███████╗██████╗ \n",
    "████╗ ████║██║╚══██╔══╝██╔══██╗██╔════╝    ██╔══██╗╚══██╔══╝╚══██╔══╝██║   ██╔════╝██║ ██╔╝    ██╔════╝██╔════╝██╔══██╗██╔══██╗██╔══██╗██╔════╝██╔══██╗\n",
    "██╔████╔██║██║   ██║   ██████╔╝█████╗      ███████║   ██║      ██║████████╗██║     █████╔╝     ███████╗██║     ██████╔╝███████║██████╔╝█████╗  ██████╔╝\n",
    "██║╚██╔╝██║██║   ██║   ██╔══██╗██╔══╝      ██╔══██║   ██║      ██║██╔═██╔═╝██║     ██╔═██╗     ╚════██║██║     ██╔══██╗██╔══██║██╔═══╝ ██╔══╝  ██╔══██╗\n",
    "██║ ╚═╝ ██║██║   ██║   ██║  ██║███████╗    ██║  ██║   ██║      ██║██████║  ╚██████╗██║  ██╗    ███████║╚██████╗██║  ██║██║  ██║██║     ███████╗██║  ██║\n",
    "╚═╝     ╚═╝╚═╝   ╚═╝   ╚═╝  ╚═╝╚══════╝    ╚═╝  ╚═╝   ╚═╝      ╚═╝╚═════╝   ╚═════╝╚═╝  ╚═╝    ╚══════╝ ╚═════╝╚═╝  ╚═╝╚═╝  ╚═╝╚═╝     ╚══════╝╚═╝  ╚═╝\n",
    "                                                                                                                                                       \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import json\n",
    "url_main_page_MIITREATTACK='https://attack.mitre.org/'\n",
    "website_main_page_MITREATTACK=requests.get(url_main_page_MIITREATTACK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [版本紀錄](https://attack.mitre.org/resources/versions/)\n",
    "先前的MITRE ATT&CK的版本從v3到v15是有網址的，而v1、v2並沒有提供網址。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://attack.mitre.org/versions/v3/\n",
      "https://attack.mitre.org/versions/v3/\n",
      "https://attack.mitre.org/versions/v4/\n",
      "https://attack.mitre.org/versions/v5/\n",
      "https://attack.mitre.org/versions/v6/\n",
      "https://attack.mitre.org/versions/v7/\n",
      "https://attack.mitre.org/versions/v8/\n",
      "https://attack.mitre.org/versions/v9/\n",
      "https://attack.mitre.org/versions/v10/\n",
      "https://attack.mitre.org/versions/v11/\n",
      "https://attack.mitre.org/versions/v12/\n",
      "https://attack.mitre.org/versions/v13/\n",
      "https://attack.mitre.org/versions/v14/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "number=3\n",
    "for version in range(3,16):    \n",
    "    url_main_page_MIITREATTACK=f'https://attack.mitre.org/versions/v{number}/'\n",
    "    number=version\n",
    "    website_main_page_MITREATTACK=requests.get(url_MIITREATTACK_main_page)\n",
    "    #print(version)\n",
    "    print(url_main_page_MIITREATTACK)\n",
    "    with open(os.path.join(os.getcwd(),\"data\",\"versions\",f\"html_mainpage{number}\"),\"w\",encoding='utf-8')as html_mainpage:\n",
    "        html_mainpage.write(website_main_page_MITREATTACK.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 簡易版列表資訊爬蟲\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## technique_scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def technique_scraper():\n",
    "    dict_techniques={\"enterprise\":{},\"mobile\":{},\"ics\":{}}\n",
    "    def description_filter(tr_content):\n",
    "        #print(p_tag)\n",
    "        if tr_content['class'][0]==\"technique\":\n",
    "            td_tag = tr_content.findAll('td')[2]\n",
    "            full_text = ''.join(td_tag.stripped_strings).strip()\n",
    "            return full_text\n",
    "        else:\n",
    "            td_tag = tr_content.findAll('td')[3]\n",
    "            full_text = ''.join(td_tag.stripped_strings).strip()\n",
    "            return full_text\n",
    "    \n",
    "    def id_filter(tr_content):\n",
    "        return tr_content.find('a').text.replace(' ','')\n",
    "    def name_filter(tr_content):\n",
    "        return tr_content.findAll('a')[1].text.strip()\n",
    "    def summarize(tr_content):\n",
    "        id=id_filter(tr_content)\n",
    "        name=name_filter(tr_content)\n",
    "        description=description_filter(tr_content)\n",
    "        dict_technique={\n",
    "            \"ID\":id,\n",
    "            \"name\":name,\n",
    "            \"description\":description,\n",
    "        }\n",
    "        return dict_technique\n",
    "    type_technique=[\"enterprise\",\"mobile\",\"ics\"]\n",
    "    for j in type_technique:\n",
    "        url=url_main_page_MIITREATTACK+\"techniques/\"+j+\"/\"\n",
    "        response=requests.get(url)\n",
    "        soup=BeautifulSoup(response.text,'html.parser')\n",
    "        content=soup.find_all(\"tr\")\n",
    "        for i in range(1,len(content)):\n",
    "            #print(content[i]['class'])\n",
    "            if content[i]['class'][0] == \"technique\":\n",
    "                dict_techniques[j][id_filter(content[i])]=summarize(content[i])\n",
    "                id_=id_filter(content[i])\n",
    "                #print(id_)\n",
    "            else:\n",
    "                dict_techniques[j][id_][id_filter(content[i])]=summarize(content[i])\n",
    "    return dict_techniques\n",
    "with open(os.path.join(os.getcwd(),\"data\",\"techniques.json\"),\"w\",encoding='utf-8')as file:\n",
    "    json.dump(technique_scraper(),file,indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## group_scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 164\n"
     ]
    }
   ],
   "source": [
    "def group_scraper():\n",
    "    dict_groups={}\n",
    "    def description_filter(tr_content):\n",
    "        p_tag = tr_content.find('p')\n",
    "        #print(p_tag)\n",
    "        full_text = ''.join(p_tag.stripped_strings).strip()\n",
    "        return full_text\n",
    "    def id_filter(tr_content):\n",
    "        return tr_content.find('a').text.replace(' ','')\n",
    "    def name_filter(tr_content):\n",
    "        return tr_content.findAll('a')[1].text.strip()\n",
    "    def summarize(tr_content):\n",
    "        id=id_filter(tr_content)\n",
    "        name=name_filter(tr_content)\n",
    "        description=description_filter(tr_content)\n",
    "        dict_group={\n",
    "            \"ID\":id,\n",
    "            \"name\":name,\n",
    "            \"description\":description\n",
    "        }\n",
    "        return dict_group\n",
    "    url=url_main_page_MIITREATTACK+\"groups/\"\n",
    "    response=requests.get(url)\n",
    "    soup=BeautifulSoup(response.text,'html.parser')\n",
    "    content=soup.find_all(\"tr\")\n",
    "    #print(content)\n",
    "    print(\"Total:\",len(content))\n",
    "    for i in range(1,len(content)):\n",
    "        #print(content[i].findAll(\"td\"))\n",
    "        #print(content[i])\n",
    "        #print(id_filter(content[i]))\n",
    "        #print(name_filter(content[i]))\n",
    "        #print(description_filter(content[i]))\n",
    "        #print(summarize(content[i]))\n",
    "        dict_groups[id_filter(content[i])]=summarize(content[i])\n",
    "    return dict_groups\n",
    "\n",
    "with open(os.path.join(os.getcwd(),\"data\",\"groups.json\"),\"w\",encoding='utf-8')as file:\n",
    "    json.dump(group_scraper(),file,indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## campaign_scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 37\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def campaign_scraper():\n",
    "    dict_campaigns={}\n",
    "    def description_filter(tr_content):\n",
    "        p_tag = tr_content.find('p')\n",
    "        #print(p_tag)\n",
    "        full_text = ''.join(p_tag.stripped_strings).strip()\n",
    "        return full_text\n",
    "    def id_filter(tr_content):\n",
    "        return tr_content.find('a').text.replace(' ','')\n",
    "    def name_filter(tr_content):\n",
    "        return tr_content.findAll('a')[1].text.strip()\n",
    "    def summarize(tr_content):\n",
    "        id=id_filter(tr_content)\n",
    "        name=name_filter(tr_content)\n",
    "        description=description_filter(tr_content)\n",
    "        dict_campaign={\n",
    "            \"ID\":id,\n",
    "            \"name\":name,\n",
    "            \"description\":description\n",
    "        }\n",
    "        return dict_campaign\n",
    "    url=url_main_page_MIITREATTACK+\"campaigns/\"\n",
    "    response=requests.get(url)\n",
    "    soup=BeautifulSoup(response.text,'html.parser')\n",
    "    content=soup.find_all(\"tr\")\n",
    "    #print(content)\n",
    "    print(\"Total:\",len(content))\n",
    "    for i in range(1,len(content)):\n",
    "        #print(content[i].findAll(\"td\"))\n",
    "        #print(content[i])\n",
    "        #print(id_filter(content[i]))\n",
    "        #print(name_filter(content[i]))\n",
    "        #print(description_filter(content[i]))\n",
    "        #print(summarize(content[i]))\n",
    "        dict_campaigns[id_filter(content[i])]=summarize(content[i])\n",
    "    return dict_campaigns\n",
    "\n",
    "with open(os.path.join(os.getcwd(),\"data\",\"campaigns.json\"),\"w\",encoding='utf-8')as file:\n",
    "    json.dump(campaign_scraper(),file,indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## software_scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 827\n"
     ]
    }
   ],
   "source": [
    "def software_scraper():\n",
    "    dict_softwares={}\n",
    "    def description_filter(tr_content):\n",
    "        p_tag = tr_content.find('p')\n",
    "        #print(p_tag)\n",
    "        full_text = ''.join(p_tag.stripped_strings).strip()\n",
    "        return full_text\n",
    "    def id_filter(tr_content):\n",
    "        return tr_content.find('a').text.replace(' ','')\n",
    "    def name_filter(tr_content):\n",
    "        return tr_content.findAll('a')[1].text.strip()\n",
    "    def associatedsoftware_filter(tr_content):\n",
    "        return tr_content.findAll('td')[2].text.strip()\n",
    "    def summarize(tr_content):\n",
    "        id=id_filter(tr_content)\n",
    "        name=name_filter(tr_content)\n",
    "        description=description_filter(tr_content)\n",
    "        associatedsoftware=associatedsoftware_filter(tr_content)\n",
    "        dict_software={\n",
    "            \"ID\":id,\n",
    "            \"name\":name,\n",
    "            \"description\":description,\n",
    "            \"Associated Software\":associatedsoftware\n",
    "        }\n",
    "        return dict_software\n",
    "    url=url_main_page_MIITREATTACK+\"software/\"\n",
    "    response=requests.get(url)\n",
    "    soup=BeautifulSoup(response.text,'html.parser')\n",
    "    content=soup.find_all(\"tr\")\n",
    "    #print(content)\n",
    "    print(\"Total:\",len(content))\n",
    "    for i in range(1,len(content)):\n",
    "        #print(content[i].findAll(\"td\"))\n",
    "        #print(content[i])\n",
    "        #print(id_filter(content[i]))\n",
    "        #print(name_filter(content[i]))\n",
    "        #print(description_filter(content[i]))\n",
    "        #print(summarize(content[i]))\n",
    "        dict_softwares[id_filter(content[i])]=summarize(content[i])\n",
    "    return dict_softwares\n",
    "\n",
    "with open(os.path.join(os.getcwd(),\"data\",\"softwares.json\"),\"w\",encoding='utf-8')as file:\n",
    "    json.dump(software_scraper(),file,indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tactic_scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tactic_scraper():\n",
    "    dict_tactics={\"enterprise\":{},\"mobile\":{},\"ics\":{}}\n",
    "    def description_filter(tr_content):\n",
    "        td_tag = tr_content.findAll('td')[2]\n",
    "        #print(p_tag)\n",
    "        full_text = ''.join(td_tag.stripped_strings).strip()\n",
    "        return full_text\n",
    "    def id_filter(tr_content):\n",
    "        return tr_content.find('a').text.replace(' ','')\n",
    "    def name_filter(tr_content):\n",
    "        return tr_content.findAll('a')[1].text.strip()\n",
    "    def summarize(tr_content):\n",
    "        id=id_filter(tr_content)\n",
    "        name=name_filter(tr_content)\n",
    "        description=description_filter(tr_content)\n",
    "        dict_tactic={\n",
    "            \"ID\":id,\n",
    "            \"name\":name,\n",
    "            \"description\":description,\n",
    "        }\n",
    "        return dict_tactic\n",
    "    type_tactic=[\"enterprise\",\"mobile\",\"ics\"]\n",
    "    for j in type_tactic:\n",
    "        url=url_main_page_MIITREATTACK+\"tactics/\"+j+\"/\"\n",
    "        response=requests.get(url)\n",
    "        soup=BeautifulSoup(response.text,'html.parser')\n",
    "        content=soup.find_all(\"tr\")\n",
    "        for i in range(1,len(content)):\n",
    "            dict_tactics[j][id_filter(content[i])]=summarize(content[i])\n",
    "    return dict_tactics\n",
    "with open(os.path.join(os.getcwd(),\"data\",\"tactics.json\"),\"w\",encoding='utf-8')as file:\n",
    "    json.dump(tactic_scraper(),file,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 164\n",
      "Total: 827\n",
      "Total: 37\n"
     ]
    }
   ],
   "source": [
    "list_href_v16={\n",
    "    \"tactic\":tactic_scraper(),\n",
    "    \"technique\":technique_scraper(),\n",
    "    \"groups\":group_scraper(),\n",
    "    \"software\":software_scraper(),\n",
    "    \"campaigns\":campaign_scraper()\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.getcwd(),\"data\",\"list_href_v16.json\"),\"w\",encoding='utf-8')as file:\n",
    "    json.dump(list_href_v16,file,indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 詳細版本資訊爬蟲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decriptiion_filter():\n",
    "    return\n",
    "def subtechnique_filter():\n",
    "    return\n",
    "def procedureexample_summarizer():\n",
    "    return\n",
    "def mitigation_summarizer():\n",
    "    return\n",
    "def detection_summarizer():\n",
    "    return\n",
    "def reference_summarizer():\n",
    "    return\n",
    "def rowcarddata_reader():\n",
    "    return\n",
    "def table_reader():\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
